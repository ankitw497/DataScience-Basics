{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert\" style=\"background-color:#fff; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#006a79; font-size:40px'> Bivariate Analysis</h1>\n",
    "</div>\n",
    "\n",
    "“Bi” means “two” and \"variate\" means variable, Hence it's the analysis of 2 variables. \n",
    "\n",
    "The main goal of bivariate analysis is to find relationship between two variables in the data.\n",
    "\n",
    "## Content:\n",
    "- Correlation and Correlation Test\n",
    "- Chi-Squared Test\n",
    "- ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Automobile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>...</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling normalized-losses         make fuel-type aspiration num-of-doors  \\\n",
       "0          3                 ?  alfa-romero       gas        std          two   \n",
       "1          3                 ?  alfa-romero       gas        std          two   \n",
       "2          1                 ?  alfa-romero       gas        std          two   \n",
       "3          2               164         audi       gas        std         four   \n",
       "4          2               164         audi       gas        std         four   \n",
       "\n",
       "    body-style drive-wheels engine-location  wheel-base  ...  engine-size  \\\n",
       "0  convertible          rwd           front        88.6  ...          130   \n",
       "1  convertible          rwd           front        88.6  ...          130   \n",
       "2    hatchback          rwd           front        94.5  ...          152   \n",
       "3        sedan          fwd           front        99.8  ...          109   \n",
       "4        sedan          4wd           front        99.4  ...          136   \n",
       "\n",
       "   fuel-system  bore  stroke compression-ratio horsepower  peak-rpm city-mpg  \\\n",
       "0         mpfi  3.47    2.68               9.0        111      5000       21   \n",
       "1         mpfi  3.47    2.68               9.0        111      5000       21   \n",
       "2         mpfi  2.68    3.47               9.0        154      5000       19   \n",
       "3         mpfi  3.19     3.4              10.0        102      5500       24   \n",
       "4         mpfi  3.19     3.4               8.0        115      5500       18   \n",
       "\n",
       "  highway-mpg  price  \n",
       "0          27  13495  \n",
       "1          27  16500  \n",
       "2          26  16500  \n",
       "3          30  13950  \n",
       "4          22  17450  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Datasets/Automobile_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "df['price'] = df['price'].astype(int)\n",
    "\n",
    "df['horsepower'] = df['horsepower'].replace(\"?\", np.nan)\n",
    "df = df.dropna()\n",
    "df['horsepower'] = df['horsepower'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>1. Correlation and Correlation Test</h2>\n",
    "</div>\n",
    "\n",
    "Correlation is the statitistical measure of the strength of linear relationship between 2 variables. In other words it describes how are 2 variables moving with each other.\n",
    "\n",
    "The value of correlation coffecients ranges from -1 to 1. \n",
    "- -1 states that the variables move in the opposite direction with the same intensity\n",
    "- 0 states that the variables don't have any relationship\n",
    "- 1 states that the varaibles move in the same direction with the same intensity\n",
    "\n",
    "There are various types of correlations. The most important one is pearson correlation.\n",
    "\n",
    "#### Pearson Correlation Coefficient\n",
    "\n",
    "$$r = \\frac{{}\\sum_{i=1}^{n} (x_i - \\overline{x})(y_i - \\overline{y})}\n",
    "{\\sqrt{\\sum_{i=1}^{n} (x_i - \\overline{x})^2(y_i - \\overline{y})^2}}$$\n",
    "\n",
    "#### Linear Correlation Coefficient\n",
    "\n",
    "At lots of places you might see the below given formula for correlation\n",
    "\n",
    "$$r = \\frac{{}\\sum x y - \\sum x \\sum y}\n",
    "{\\sqrt{[n\\sum x^2 - (\\sum x)^2][n\\sum y^2 - (\\sum y)^2]}}$$\n",
    "\n",
    "\n",
    "While computing the correlation, you can compute the associated p-value as well to check the statistical significane of the correlation test.\n",
    "\n",
    "**Null hypothesis (H0):** There is no relation between the variables. \n",
    "\n",
    "**Alternate hypothesis (H1):** There is a statistical significant relation between the two variables.\n",
    "\n",
    "\n",
    "Let's compute the correlation coeffiecient between 'horsepower' and 'price' features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malternative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'two-sided'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Pearson correlation coefficient and p-value for testing non-correlation.\n",
      "\n",
      "The Pearson correlation coefficient [1]_ measures the linear relationship\n",
      "between two datasets. Like other correlation\n",
      "coefficients, this one varies between -1 and +1 with 0 implying no\n",
      "correlation. Correlations of -1 or +1 imply an exact linear relationship.\n",
      "Positive correlations imply that as x increases, so does y. Negative\n",
      "correlations imply that as x increases, y decreases.\n",
      "\n",
      "This function also performs a test of the null hypothesis that the\n",
      "distributions underlying the samples are uncorrelated and normally\n",
      "distributed. (See Kowalski [3]_\n",
      "for a discussion of the effects of non-normality of the input on the\n",
      "distribution of the correlation coefficient.)\n",
      "The p-value roughly indicates the probability of an uncorrelated system\n",
      "producing datasets that have a Pearson correlation at least as extreme\n",
      "as the one computed from these datasets.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x : (N,) array_like\n",
      "    Input array.\n",
      "y : (N,) array_like\n",
      "    Input array.\n",
      "alternative : {'two-sided', 'greater', 'less'}, optional\n",
      "    Defines the alternative hypothesis. Default is 'two-sided'.\n",
      "    The following options are available:\n",
      "\n",
      "    * 'two-sided': the correlation is nonzero\n",
      "    * 'less': the correlation is negative (less than zero)\n",
      "    * 'greater':  the correlation is positive (greater than zero)\n",
      "\n",
      "    .. versionadded:: 1.9.0\n",
      "method : ResamplingMethod, optional\n",
      "    Defines the method used to compute the p-value. If `method` is an\n",
      "    instance of `PermutationMethod`/`MonteCarloMethod`, the p-value is\n",
      "    computed using\n",
      "    `scipy.stats.permutation_test`/`scipy.stats.monte_carlo_test` with the\n",
      "    provided configuration options and other appropriate settings.\n",
      "    Otherwise, the p-value is computed as documented in the notes.\n",
      "\n",
      "    .. versionadded:: 1.11.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "result : `~scipy.stats._result_classes.PearsonRResult`\n",
      "    An object with the following attributes:\n",
      "\n",
      "    statistic : float\n",
      "        Pearson product-moment correlation coefficient.\n",
      "    pvalue : float\n",
      "        The p-value associated with the chosen alternative.\n",
      "\n",
      "    The object has the following method:\n",
      "\n",
      "    confidence_interval(confidence_level, method)\n",
      "        This computes the confidence interval of the correlation\n",
      "        coefficient `statistic` for the given confidence level.\n",
      "        The confidence interval is returned in a ``namedtuple`` with\n",
      "        fields `low` and `high`. If `method` is not provided, the\n",
      "        confidence interval is computed using the Fisher transformation\n",
      "        [1]_. If `method` is an instance of `BootstrapMethod`, the\n",
      "        confidence interval is computed using `scipy.stats.bootstrap` with\n",
      "        the provided configuration options and other appropriate settings.\n",
      "        In some cases, confidence limits may be NaN due to a degenerate\n",
      "        resample, and this is typical for very small samples (~6\n",
      "        observations).\n",
      "\n",
      "Warns\n",
      "-----\n",
      "`~scipy.stats.ConstantInputWarning`\n",
      "    Raised if an input is a constant array.  The correlation coefficient\n",
      "    is not defined in this case, so ``np.nan`` is returned.\n",
      "\n",
      "`~scipy.stats.NearConstantInputWarning`\n",
      "    Raised if an input is \"nearly\" constant.  The array ``x`` is considered\n",
      "    nearly constant if ``norm(x - mean(x)) < 1e-13 * abs(mean(x))``.\n",
      "    Numerical errors in the calculation ``x - mean(x)`` in this case might\n",
      "    result in an inaccurate calculation of r.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "spearmanr : Spearman rank-order correlation coefficient.\n",
      "kendalltau : Kendall's tau, a correlation measure for ordinal data.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The correlation coefficient is calculated as follows:\n",
      "\n",
      ".. math::\n",
      "\n",
      "    r = \\frac{\\sum (x - m_x) (y - m_y)}\n",
      "             {\\sqrt{\\sum (x - m_x)^2 \\sum (y - m_y)^2}}\n",
      "\n",
      "where :math:`m_x` is the mean of the vector x and :math:`m_y` is\n",
      "the mean of the vector y.\n",
      "\n",
      "Under the assumption that x and y are drawn from\n",
      "independent normal distributions (so the population correlation coefficient\n",
      "is 0), the probability density function of the sample correlation\n",
      "coefficient r is ([1]_, [2]_):\n",
      "\n",
      ".. math::\n",
      "    f(r) = \\frac{{(1-r^2)}^{n/2-2}}{\\mathrm{B}(\\frac{1}{2},\\frac{n}{2}-1)}\n",
      "\n",
      "where n is the number of samples, and B is the beta function.  This\n",
      "is sometimes referred to as the exact distribution of r.  This is\n",
      "the distribution that is used in `pearsonr` to compute the p-value when\n",
      "the `method` parameter is left at its default value (None).\n",
      "The distribution is a beta distribution on the interval [-1, 1],\n",
      "with equal shape parameters a = b = n/2 - 1.  In terms of SciPy's\n",
      "implementation of the beta distribution, the distribution of r is::\n",
      "\n",
      "    dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
      "\n",
      "The default p-value returned by `pearsonr` is a two-sided p-value. For a\n",
      "given sample with correlation coefficient r, the p-value is\n",
      "the probability that abs(r') of a random sample x' and y' drawn from\n",
      "the population with zero correlation would be greater than or equal\n",
      "to abs(r). In terms of the object ``dist`` shown above, the p-value\n",
      "for a given r and length n can be computed as::\n",
      "\n",
      "    p = 2*dist.cdf(-abs(r))\n",
      "\n",
      "When n is 2, the above continuous distribution is not well-defined.\n",
      "One can interpret the limit of the beta distribution as the shape\n",
      "parameters a and b approach a = b = 0 as a discrete distribution with\n",
      "equal probability masses at r = 1 and r = -1.  More directly, one\n",
      "can observe that, given the data x = [x1, x2] and y = [y1, y2], and\n",
      "assuming x1 != x2 and y1 != y2, the only possible values for r are 1\n",
      "and -1.  Because abs(r') for any sample x' and y' with length 2 will\n",
      "be 1, the two-sided p-value for a sample of length 2 is always 1.\n",
      "\n",
      "For backwards compatibility, the object that is returned also behaves\n",
      "like a tuple of length two that holds the statistic and the p-value.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] \"Pearson correlation coefficient\", Wikipedia,\n",
      "       https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
      ".. [2] Student, \"Probable error of a correlation coefficient\",\n",
      "       Biometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.\n",
      ".. [3] C. J. Kowalski, \"On the Effects of Non-Normality on the Distribution\n",
      "       of the Sample Product-Moment Correlation Coefficient\"\n",
      "       Journal of the Royal Statistical Society. Series C (Applied\n",
      "       Statistics), Vol. 21, No. 1 (1972), pp. 1-12.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from scipy import stats\n",
      ">>> x, y = [1, 2, 3, 4, 5, 6, 7], [10, 9, 2.5, 6, 4, 3, 2]\n",
      ">>> res = stats.pearsonr(x, y)\n",
      ">>> res\n",
      "PearsonRResult(statistic=-0.828503883588428, pvalue=0.021280260007523286)\n",
      "\n",
      "To perform an exact permutation version of the test:\n",
      "\n",
      ">>> rng = np.random.default_rng(7796654889291491997)\n",
      ">>> method = stats.PermutationMethod(n_resamples=np.inf, random_state=rng)\n",
      ">>> stats.pearsonr(x, y, method=method)\n",
      "PearsonRResult(statistic=-0.828503883588428, pvalue=0.028174603174603175)\n",
      "\n",
      "To perform the test under the null hypothesis that the data were drawn from\n",
      "*uniform* distributions:\n",
      "\n",
      ">>> method = stats.MonteCarloMethod(rvs=(rng.uniform, rng.uniform))\n",
      ">>> stats.pearsonr(x, y, method=method)\n",
      "PearsonRResult(statistic=-0.828503883588428, pvalue=0.0188)\n",
      "\n",
      "To produce an asymptotic 90% confidence interval:\n",
      "\n",
      ">>> res.confidence_interval(confidence_level=0.9)\n",
      "ConfidenceInterval(low=-0.9644331982722841, high=-0.3460237473272273)\n",
      "\n",
      "And for a bootstrap confidence interval:\n",
      "\n",
      ">>> method = stats.BootstrapMethod(method='BCa', random_state=rng)\n",
      ">>> res.confidence_interval(confidence_level=0.9, method=method)\n",
      "ConfidenceInterval(low=-0.9983163756488651, high=-0.22771001702132443)  # may vary\n",
      "\n",
      "There is a linear dependence between x and y if y = a + b*x + e, where\n",
      "a,b are constants and e is a random error term, assumed to be independent\n",
      "of x. For simplicity, assume that x is standard normal, a=0, b=1 and let\n",
      "e follow a normal distribution with mean zero and standard deviation s>0.\n",
      "\n",
      ">>> rng = np.random.default_rng()\n",
      ">>> s = 0.5\n",
      ">>> x = stats.norm.rvs(size=500, random_state=rng)\n",
      ">>> e = stats.norm.rvs(scale=s, size=500, random_state=rng)\n",
      ">>> y = x + e\n",
      ">>> stats.pearsonr(x, y).statistic\n",
      "0.9001942438244763\n",
      "\n",
      "This should be close to the exact value given by\n",
      "\n",
      ">>> 1/np.sqrt(1 + s**2)\n",
      "0.8944271909999159\n",
      "\n",
      "For s=0.5, we observe a high level of correlation. In general, a large\n",
      "variance of the noise reduces the correlation, while the correlation\n",
      "approaches one as the variance of the error goes to zero.\n",
      "\n",
      "It is important to keep in mind that no correlation does not imply\n",
      "independence unless (x, y) is jointly normal. Correlation can even be zero\n",
      "when there is a very simple dependence structure: if X follows a\n",
      "standard normal distribution, let y = abs(x). Note that the correlation\n",
      "between x and y is zero. Indeed, since the expectation of x is zero,\n",
      "cov(x, y) = E[x*y]. By definition, this equals E[x*abs(x)] which is zero\n",
      "by symmetry. The following lines of code illustrate this observation:\n",
      "\n",
      ">>> y = np.abs(x)\n",
      ">>> stats.pearsonr(x, y)\n",
      "PearsonRResult(statistic=-0.05444919272687482, pvalue=0.22422294836207743)\n",
      "\n",
      "A non-zero correlation coefficient can be misleading. For example, if X has\n",
      "a standard normal distribution, define y = x if x < 0 and y = 0 otherwise.\n",
      "A simple calculation shows that corr(x, y) = sqrt(2/Pi) = 0.797...,\n",
      "implying a high level of correlation:\n",
      "\n",
      ">>> y = np.where(x < 0, x, 0)\n",
      ">>> stats.pearsonr(x, y)\n",
      "PearsonRResult(statistic=0.861985781588, pvalue=4.813432002751103e-149)\n",
      "\n",
      "This is unintuitive since there is no dependence of x and y if x is larger\n",
      "than zero which happens in about half of the cases if we sample x and y.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/scipy/stats/_stats_py.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "# Pearson's correlation\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "?pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      111\n",
       "1      111\n",
       "2      154\n",
       "3      102\n",
       "4      115\n",
       "      ... \n",
       "200    114\n",
       "201    160\n",
       "202    134\n",
       "203    106\n",
       "204    114\n",
       "Name: horsepower, Length: 205, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['horsepower'].replace(\"?\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U5')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c0/864x3m2528sf2dfbw9r32jkm0000gn/T/ipykernel_28282/3117232433.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;31m# calculate Pearson's correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'horsepower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pearsons correlation: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, alternative, method)\u001b[0m\n\u001b[1;32m   4770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4771\u001b[0m     \u001b[0;31m# dtype is the data type for the calculations.  This expression ensures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4772\u001b[0m     \u001b[0;31m# that the data type is at least 64 bit floating point.  It might have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     \u001b[0;31m# more precision if the input is, for example, np.longdouble.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4774\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4777\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U5')) -> None"
     ]
    }
   ],
   "source": [
    "# calculate Pearson's correlation\n",
    "\n",
    "corr, _ = pearsonr(df['horsepower'].replace(\"?\",0).astype(int), df['price'])\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('p-value: ', _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '?'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# calculate Spearman's correlation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spearmanr\n\u001b[0;32m----> 4\u001b[0m corr, _ \u001b[38;5;241m=\u001b[39m spearmanr(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhorsepower\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpearman correlation: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m corr)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp-value: \u001b[39m\u001b[38;5;124m'\u001b[39m, _)\n",
      "File \u001b[0;32m~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '?'"
     ]
    }
   ],
   "source": [
    "# calculate Spearman's correlation\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "corr, _ = spearmanr(df['horsepower'].astype(float), df['price'])\n",
    "print('Spearman correlation: %.3f' % corr)\n",
    "print('p-value: ', _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>2. Chi Squre Test</h2>\n",
    "</div>\n",
    "\n",
    "Chi-squared test is used to test if two categorical variables are dependent, by means of a contingency table.\n",
    "\n",
    "**Null hypothesis (H0):** There is no relation between the categorical variables. \n",
    "\n",
    "**Alternate hypothesis (H1):** There is a statistical significant relation between the two categorical variables.\n",
    "\n",
    "Let's check if 'sex' and 'Survived' features are dependent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"../Datasets/titanic.csv\")\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mchi2_contingency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Chi-square test of independence of variables in a contingency table.\n",
      "\n",
      "This function computes the chi-square statistic and p-value for the\n",
      "hypothesis test of independence of the observed frequencies in the\n",
      "contingency table [1]_ `observed`.  The expected frequencies are computed\n",
      "based on the marginal sums under the assumption of independence; see\n",
      "`scipy.stats.contingency.expected_freq`.  The number of degrees of\n",
      "freedom is (expressed using numpy functions and attributes)::\n",
      "\n",
      "    dof = observed.size - sum(observed.shape) + observed.ndim - 1\n",
      "\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "observed : array_like\n",
      "    The contingency table. The table contains the observed frequencies\n",
      "    (i.e. number of occurrences) in each category.  In the two-dimensional\n",
      "    case, the table is often described as an \"R x C table\".\n",
      "correction : bool, optional\n",
      "    If True, *and* the degrees of freedom is 1, apply Yates' correction\n",
      "    for continuity.  The effect of the correction is to adjust each\n",
      "    observed value by 0.5 towards the corresponding expected value.\n",
      "lambda_ : float or str, optional\n",
      "    By default, the statistic computed in this test is Pearson's\n",
      "    chi-squared statistic [2]_.  `lambda_` allows a statistic from the\n",
      "    Cressie-Read power divergence family [3]_ to be used instead.  See\n",
      "    `scipy.stats.power_divergence` for details.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "res : Chi2ContingencyResult\n",
      "    An object containing attributes:\n",
      "\n",
      "    statistic : float\n",
      "        The test statistic.\n",
      "    pvalue : float\n",
      "        The p-value of the test.\n",
      "    dof : int\n",
      "        The degrees of freedom.\n",
      "    expected_freq : ndarray, same shape as `observed`\n",
      "        The expected frequencies, based on the marginal sums of the table.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "scipy.stats.contingency.expected_freq\n",
      "scipy.stats.fisher_exact\n",
      "scipy.stats.chisquare\n",
      "scipy.stats.power_divergence\n",
      "scipy.stats.barnard_exact\n",
      "scipy.stats.boschloo_exact\n",
      "\n",
      "Notes\n",
      "-----\n",
      "An often quoted guideline for the validity of this calculation is that\n",
      "the test should be used only if the observed and expected frequencies\n",
      "in each cell are at least 5.\n",
      "\n",
      "This is a test for the independence of different categories of a\n",
      "population. The test is only meaningful when the dimension of\n",
      "`observed` is two or more.  Applying the test to a one-dimensional\n",
      "table will always result in `expected` equal to `observed` and a\n",
      "chi-square statistic equal to 0.\n",
      "\n",
      "This function does not handle masked arrays, because the calculation\n",
      "does not make sense with missing values.\n",
      "\n",
      "Like `scipy.stats.chisquare`, this function computes a chi-square\n",
      "statistic; the convenience this function provides is to figure out the\n",
      "expected frequencies and degrees of freedom from the given contingency\n",
      "table. If these were already known, and if the Yates' correction was not\n",
      "required, one could use `scipy.stats.chisquare`.  That is, if one calls::\n",
      "\n",
      "    res = chi2_contingency(obs, correction=False)\n",
      "\n",
      "then the following is true::\n",
      "\n",
      "    (res.statistic, res.pvalue) == stats.chisquare(obs.ravel(),\n",
      "                                                   f_exp=ex.ravel(),\n",
      "                                                   ddof=obs.size - 1 - dof)\n",
      "\n",
      "The `lambda_` argument was added in version 0.13.0 of scipy.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] \"Contingency table\",\n",
      "       https://en.wikipedia.org/wiki/Contingency_table\n",
      ".. [2] \"Pearson's chi-squared test\",\n",
      "       https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test\n",
      ".. [3] Cressie, N. and Read, T. R. C., \"Multinomial Goodness-of-Fit\n",
      "       Tests\", J. Royal Stat. Soc. Series B, Vol. 46, No. 3 (1984),\n",
      "       pp. 440-464.\n",
      ".. [4] Berger, Jeffrey S. et al. \"Aspirin for the Primary Prevention of\n",
      "       Cardiovascular Events in Women and Men: A Sex-Specific\n",
      "       Meta-analysis of Randomized Controlled Trials.\"\n",
      "       JAMA, 295(3):306-313, :doi:`10.1001/jama.295.3.306`, 2006.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "In [4]_, the use of aspirin to prevent cardiovascular events in women\n",
      "and men was investigated. The study notably concluded:\n",
      "\n",
      "    ...aspirin therapy reduced the risk of a composite of\n",
      "    cardiovascular events due to its effect on reducing the risk of\n",
      "    ischemic stroke in women [...]\n",
      "\n",
      "The article lists studies of various cardiovascular events. Let's\n",
      "focus on the ischemic stoke in women.\n",
      "\n",
      "The following table summarizes the results of the experiment in which\n",
      "participants took aspirin or a placebo on a regular basis for several\n",
      "years. Cases of ischemic stroke were recorded::\n",
      "\n",
      "                      Aspirin   Control/Placebo\n",
      "    Ischemic stroke     176           230\n",
      "    No stroke         21035         21018\n",
      "\n",
      "Is there evidence that the aspirin reduces the risk of ischemic stroke?\n",
      "We begin by formulating a null hypothesis :math:`H_0`:\n",
      "\n",
      "    The effect of aspirin is equivalent to that of placebo.\n",
      "\n",
      "Let's assess the plausibility of this hypothesis with\n",
      "a chi-square test.\n",
      "\n",
      ">>> import numpy as np\n",
      ">>> from scipy.stats import chi2_contingency\n",
      ">>> table = np.array([[176, 230], [21035, 21018]])\n",
      ">>> res = chi2_contingency(table)\n",
      ">>> res.statistic\n",
      "6.892569132546561\n",
      ">>> res.pvalue\n",
      "0.008655478161175739\n",
      "\n",
      "Using a significance level of 5%, we would reject the null hypothesis in\n",
      "favor of the alternative hypothesis: \"the effect of aspirin\n",
      "is not equivalent to the effect of placebo\".\n",
      "Because `scipy.stats.contingency.chi2_contingency` performs a two-sided\n",
      "test, the alternative hypothesis does not indicate the direction of the\n",
      "effect. We can use `stats.contingency.odds_ratio` to support the\n",
      "conclusion that aspirin *reduces* the risk of ischemic stroke.\n",
      "\n",
      "Below are further examples showing how larger contingency tables can be\n",
      "tested.\n",
      "\n",
      "A two-way example (2 x 3):\n",
      "\n",
      ">>> obs = np.array([[10, 10, 20], [20, 20, 20]])\n",
      ">>> res = chi2_contingency(obs)\n",
      ">>> res.statistic\n",
      "2.7777777777777777\n",
      ">>> res.pvalue\n",
      "0.24935220877729619\n",
      ">>> res.dof\n",
      "2\n",
      ">>> res.expected_freq\n",
      "array([[ 12.,  12.,  16.],\n",
      "       [ 18.,  18.,  24.]])\n",
      "\n",
      "Perform the test using the log-likelihood ratio (i.e. the \"G-test\")\n",
      "instead of Pearson's chi-squared statistic.\n",
      "\n",
      ">>> res = chi2_contingency(obs, lambda_=\"log-likelihood\")\n",
      ">>> res.statistic\n",
      "2.7688587616781319\n",
      ">>> res.pvalue\n",
      "0.25046668010954165\n",
      "\n",
      "A four-way example (2 x 2 x 2 x 2):\n",
      "\n",
      ">>> obs = np.array(\n",
      "...     [[[[12, 17],\n",
      "...        [11, 16]],\n",
      "...       [[11, 12],\n",
      "...        [15, 16]]],\n",
      "...      [[[23, 15],\n",
      "...        [30, 22]],\n",
      "...       [[14, 17],\n",
      "...        [15, 16]]]])\n",
      ">>> res = chi2_contingency(obs)\n",
      ">>> res.statistic\n",
      "8.7584514426741897\n",
      ">>> res.pvalue\n",
      "0.64417725029295503\n",
      "\u001b[0;31mFile:\u001b[0m      ~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/scipy/stats/contingency.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "# Chi Squre test\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "?chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>81</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>468</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived    0    1\n",
       "Sex               \n",
       "female     81  233\n",
       "male      468  109"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compute the contingency table\n",
    "temp = pd.crosstab(titanic_df['Sex'], titanic_df['Survived'].astype('category'))\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chisquared=260.71702,   p-value=0.00000\n"
     ]
    }
   ],
   "source": [
    "# Chi-square stat , p-value, degrees of freedom, expected frequencies\n",
    "stat, p, dof, expected = chi2_contingency(temp)\n",
    "print('chisquared=%.5f,   p-value=%.5f' % (stat, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value is 1.197357062775565e-58\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value is \" + str(p))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the p value is less than the significance level, you can reject the H0. The two variables are related. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>3. ANOVA Test</h2>\n",
    "</div>\n",
    "\n",
    "Anova test is used to test if two groups have statistically significantly different means. There are 3 types of ANOVA test.\n",
    "\n",
    "- One-way ANOVA\n",
    "- Two-way ANOVA\n",
    "- MANOVA\n",
    "\n",
    "Most of the time, One-way ANOVA is used. Let's understand One-way ANOVA in detail\n",
    "\n",
    "**Null hypothesis (H0):** The mean of two groups is same.\n",
    "\n",
    "**Alternate hypothesis (H1):** The mean of two groups is different.\n",
    "\n",
    "Let's check if mean age is the same for people who survived and people who didn't survive. In other words, the aim is to check if 'age' has any impact on the chances of person being saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"../Datasets/titanic.csv\")\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA with scipy.stats api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mf_oneway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'propagate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Perform one-way ANOVA.\n",
      "\n",
      "The one-way ANOVA tests the null hypothesis that two or more groups have\n",
      "the same population mean.  The test is applied to samples from two or\n",
      "more groups, possibly with differing sizes.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "sample1, sample2, ... : array_like\n",
      "    The sample measurements for each group.  There must be at least\n",
      "    two arguments.  If the arrays are multidimensional, then all the\n",
      "    dimensions of the array must be the same except for `axis`.\n",
      "axis : int or None, default: 0\n",
      "    If an int, the axis of the input along which to compute the statistic.\n",
      "    The statistic of each axis-slice (e.g. row) of the input will appear in a\n",
      "    corresponding element of the output.\n",
      "    If ``None``, the input will be raveled before computing the statistic.\n",
      "nan_policy : {'propagate', 'omit', 'raise'}\n",
      "    Defines how to handle input NaNs.\n",
      "    \n",
      "    - ``propagate``: if a NaN is present in the axis slice (e.g. row) along\n",
      "      which the  statistic is computed, the corresponding entry of the output\n",
      "      will be NaN.\n",
      "    - ``omit``: NaNs will be omitted when performing the calculation.\n",
      "      If insufficient data remains in the axis slice along which the\n",
      "      statistic is computed, the corresponding entry of the output will be\n",
      "      NaN.\n",
      "    - ``raise``: if a NaN is present, a ``ValueError`` will be raised.\n",
      "keepdims : bool, default: False\n",
      "    If this is set to True, the axes which are reduced are left\n",
      "    in the result as dimensions with size one. With this option,\n",
      "    the result will broadcast correctly against the input array.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "statistic : float\n",
      "    The computed F statistic of the test.\n",
      "pvalue : float\n",
      "    The associated p-value from the F distribution.\n",
      "\n",
      "Warns\n",
      "-----\n",
      "`~scipy.stats.ConstantInputWarning`\n",
      "    Raised if all values within each of the input arrays are identical.\n",
      "    In this case the F statistic is either infinite or isn't defined,\n",
      "    so ``np.inf`` or ``np.nan`` is returned.\n",
      "`~scipy.stats.DegenerateDataWarning`\n",
      "    Raised if the length of any input array is 0, or if all the input\n",
      "    arrays have length 1.  ``np.nan`` is returned for the F statistic\n",
      "    and the p-value in these cases.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The ANOVA test has important assumptions that must be satisfied in order\n",
      "for the associated p-value to be valid.\n",
      "\n",
      "1. The samples are independent.\n",
      "2. Each sample is from a normally distributed population.\n",
      "3. The population standard deviations of the groups are all equal.  This\n",
      "   property is known as homoscedasticity.\n",
      "\n",
      "If these assumptions are not true for a given set of data, it may still\n",
      "be possible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`) or\n",
      "the Alexander-Govern test (`scipy.stats.alexandergovern`) although with\n",
      "some loss of power.\n",
      "\n",
      "The length of each group must be at least one, and there must be at\n",
      "least one group with length greater than one.  If these conditions\n",
      "are not satisfied, a warning is generated and (``np.nan``, ``np.nan``)\n",
      "is returned.\n",
      "\n",
      "If all values in each group are identical, and there exist at least two\n",
      "groups with different values, the function generates a warning and\n",
      "returns (``np.inf``, 0).\n",
      "\n",
      "If all values in all groups are the same, function generates a warning\n",
      "and returns (``np.nan``, ``np.nan``).\n",
      "\n",
      "The algorithm is from Heiman [2]_, pp.394-7.\n",
      "\n",
      "Beginning in SciPy 1.9, ``np.matrix`` inputs (not recommended for new\n",
      "code) are converted to ``np.ndarray`` before the calculation is performed. In\n",
      "this case, the output will be a scalar or ``np.ndarray`` of appropriate shape\n",
      "rather than a 2D ``np.matrix``. Similarly, while masked elements of masked\n",
      "arrays are ignored, the output will be a scalar or ``np.ndarray`` rather than a\n",
      "masked array with ``mask=False``.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] R. Lowry, \"Concepts and Applications of Inferential Statistics\",\n",
      "       Chapter 14, 2014, http://vassarstats.net/textbook/\n",
      "\n",
      ".. [2] G.W. Heiman, \"Understanding research methods and statistics: An\n",
      "       integrated introduction for psychology\", Houghton, Mifflin and\n",
      "       Company, 2001.\n",
      "\n",
      ".. [3] G.H. McDonald, \"Handbook of Biological Statistics\", One-way ANOVA.\n",
      "       http://www.biostathandbook.com/onewayanova.html\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from scipy.stats import f_oneway\n",
      "\n",
      "Here are some data [3]_ on a shell measurement (the length of the anterior\n",
      "adductor muscle scar, standardized by dividing by length) in the mussel\n",
      "Mytilus trossulus from five locations: Tillamook, Oregon; Newport, Oregon;\n",
      "Petersburg, Alaska; Magadan, Russia; and Tvarminne, Finland, taken from a\n",
      "much larger data set used in McDonald et al. (1991).\n",
      "\n",
      ">>> tillamook = [0.0571, 0.0813, 0.0831, 0.0976, 0.0817, 0.0859, 0.0735,\n",
      "...              0.0659, 0.0923, 0.0836]\n",
      ">>> newport = [0.0873, 0.0662, 0.0672, 0.0819, 0.0749, 0.0649, 0.0835,\n",
      "...            0.0725]\n",
      ">>> petersburg = [0.0974, 0.1352, 0.0817, 0.1016, 0.0968, 0.1064, 0.105]\n",
      ">>> magadan = [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764,\n",
      "...            0.0689]\n",
      ">>> tvarminne = [0.0703, 0.1026, 0.0956, 0.0973, 0.1039, 0.1045]\n",
      ">>> f_oneway(tillamook, newport, petersburg, magadan, tvarminne)\n",
      "F_onewayResult(statistic=7.121019471642447, pvalue=0.0002812242314534544)\n",
      "\n",
      "`f_oneway` accepts multidimensional input arrays.  When the inputs\n",
      "are multidimensional and `axis` is not given, the test is performed\n",
      "along the first axis of the input arrays.  For the following data, the\n",
      "test is performed three times, once for each column.\n",
      "\n",
      ">>> a = np.array([[9.87, 9.03, 6.81],\n",
      "...               [7.18, 8.35, 7.00],\n",
      "...               [8.39, 7.58, 7.68],\n",
      "...               [7.45, 6.33, 9.35],\n",
      "...               [6.41, 7.10, 9.33],\n",
      "...               [8.00, 8.24, 8.44]])\n",
      ">>> b = np.array([[6.35, 7.30, 7.16],\n",
      "...               [6.65, 6.68, 7.63],\n",
      "...               [5.72, 7.73, 6.72],\n",
      "...               [7.01, 9.19, 7.41],\n",
      "...               [7.75, 7.87, 8.30],\n",
      "...               [6.90, 7.97, 6.97]])\n",
      ">>> c = np.array([[3.31, 8.77, 1.01],\n",
      "...               [8.25, 3.24, 3.62],\n",
      "...               [6.32, 8.81, 5.19],\n",
      "...               [7.48, 8.83, 8.91],\n",
      "...               [8.59, 6.01, 6.07],\n",
      "...               [3.07, 9.72, 7.48]])\n",
      ">>> F, p = f_oneway(a, b, c)\n",
      ">>> F\n",
      "array([1.75676344, 0.03701228, 3.76439349])\n",
      ">>> p\n",
      "array([0.20630784, 0.96375203, 0.04733157])\n",
      "\u001b[0;31mFile:\u001b[0m      ~/ankitw497 github/DataScience Basics/DataScience-Basics/.venv/lib/python3.9/site-packages/scipy/stats/_stats_py.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "# f_oneway\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "?f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic=4.27119, p=0.03912\n"
     ]
    }
   ],
   "source": [
    "# significance value\n",
    "alpha = 0.05\n",
    "\n",
    "# Get F and p value\n",
    "F, p = f_oneway(titanic_df[titanic_df.Survived == 1]['Age'].dropna(),\n",
    "                titanic_df[titanic_df.Survived == 0]['Age'].dropna())\n",
    "\n",
    "# Determine whether to reject or keep null hypothesis\n",
    "print('F-statistic=%.5f, p=%.5f' % (F, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# interpret p-value\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the p value is less than the significance level, you can reject the H0. The two groups are different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA with statsmodels api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit ANOVA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model F( 1,  712) =  4.271, p =  0.0391\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(Survived)</th>\n",
       "      <td>897.187582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.271195</td>\n",
       "      <td>0.039125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>149559.448362</td>\n",
       "      <td>712.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sum_sq     df         F    PR(>F)\n",
       "C(Survived)     897.187582    1.0  4.271195  0.039125\n",
       "Residual     149559.448362  712.0       NaN       NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('Age ~ C(Survived)', titanic_df).fit()\n",
    "print(f\"Overall model F({model.df_model: .0f}, {model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")\n",
    "\n",
    "# ANOVA table\n",
    "res = sm.stats.anova_lm(model, typ=2)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the p value is less than the significance level, you can reject the H0. The two groups are different. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
